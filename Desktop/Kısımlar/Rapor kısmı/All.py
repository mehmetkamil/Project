import os
import re
import sys
import json
import sqlite3
import pandas as pd
import pdfplumber
from datetime import datetime
from PyPDF2 import PdfReader

# C# karakter sorunu iÃ§in
if sys.stdout:
    sys.stdout.reconfigure(encoding='utf-8')

# ==============================================================================
# ðŸ—„ï¸ SQLÄ°TE VERÄ°TABANI FONKSÄ°YONLARI
# ==============================================================================

def init_database(db_path):
    """SQLite veritabanÄ±nÄ± ve tabloyu oluÅŸturur."""
    try:
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            
            cursor.execute('''
            CREATE TABLE IF NOT EXISTS policeler (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                sigortali TEXT,
                tarih TEXT,
                musteri_no TEXT,
                police_no TEXT UNIQUE,
                tur TEXT,
                sirket TEXT,
                plaka TEXT,
                marka TEXT,
                tutar TEXT,
                aciklama TEXT,
                referans TEXT,
                iletisim TEXT,
                kayit_tarihi DATETIME DEFAULT CURRENT_TIMESTAMP
            )
            ''')
            # Police_no Ã¼zerinde unique constraint var, ekstra index performans iÃ§in
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_police_no ON policeler(police_no)')
            
            conn.commit()
        return True
    except Exception as e:
        if sys.stdout:
            print(f"VERÄ°TABANI OLUÅžTURMA HATASI: {type(e).__name__}: {str(e)}")
        return False

def insert_police_data(db_path, data_list):
    """PoliÃ§e verilerini SQLite'a ekler (duplikasyon kontrolÃ¼ ile)."""
    added_count = 0
    try:
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            
            for data in data_list:
                police_no = str(data.get('POLÄ°Ã‡E NO', '')).strip()
                
                # GÃ¼venlik: BoÅŸ veya geÃ§ersiz poliÃ§e numaralarÄ±nÄ± atla
                if not police_no or police_no in ("-", "nan", "None"):
                    if sys.stdout:
                        print(f"LOG: GeÃ§ersiz poliÃ§e no atlandÄ±: {data.get('SÄ°GORTALI', 'Bilinmeyen')}")
                    continue
                
                try:
                    cursor.execute('''
                    INSERT INTO policeler 
                    (sigortali, tarih, musteri_no, police_no, tur, sirket, plaka, marka, tutar, aciklama, referans, iletisim)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                    ''', (
                        data.get('SÄ°GORTALI', ''),
                        data.get('TARÄ°H', ''),
                        data.get('MÃœÅžTERÄ° NO', ''),
                        police_no,
                        data.get('TÃœR', ''),
                        data.get('ÅžÄ°RKET', ''),
                        data.get('PLAKA', ''),
                        data.get('MARKA', ''),
                        data.get('TUTAR', ''),
                        data.get('AÃ‡IKLAMA', ''),
                        data.get('REFERANS', ''),
                        data.get('Ä°LETÄ°ÅžÄ°M', '')
                    ))
                    added_count += 1
                except sqlite3.IntegrityError:
                    # UNIQUE constraint ihlali - poliÃ§e zaten var
                    if sys.stdout:
                        print(f"LOG: Duplikasyon atlandÄ± (DB): {police_no}")
                    continue
            
            conn.commit()
        return added_count
    except Exception as e:
        if sys.stdout:
            print(f"VERÄ°TABANI HATASI: {type(e).__name__}: {str(e)}")
        return added_count

# ==============================================================================
# ðŸ› ï¸ YARDIMCI METÄ°N FONKSÄ°YONLARI
# ==============================================================================

def clean_text(text):
    """Metni temizler ve tek satÄ±r haline getirir."""
    if not text: return ""
    text = text.replace("\n", " ")
    return re.sub(r'\s+', ' ', text).strip()

def normalize_amount_to_turkish(amount_str):
    """TutarÄ± TÃ¼rk formatÄ±na Ã§evirir: 1.234,56"""
    if not amount_str or amount_str == "0" or amount_str == "-":
        return amount_str
    
    # EUR gibi para birimlerini koru
    currency = ""
    if "EUR" in amount_str:
        currency = " EUR"
        amount_str = amount_str.replace("EUR", "").strip()
    
    # BoÅŸluklarÄ± temizle
    amount_str = amount_str.replace(" ", "")
    
    # VirgÃ¼l ve nokta sayÄ±sÄ±nÄ± kontrol et
    comma_count = amount_str.count(',')
    dot_count = amount_str.count('.')
    
    # Son virgÃ¼l ve noktanÄ±n pozisyonunu bul
    last_comma_pos = amount_str.rfind(',')
    last_dot_pos = amount_str.rfind('.')
    
    # DURUM 1: ABD formatÄ± - son nokta virgÃ¼lden SONRA: 19,320.11 veya 1,234.56
    # VirgÃ¼l binlik ayÄ±rÄ±cÄ±, nokta ondalÄ±k ayÄ±rÄ±cÄ±
    if comma_count >= 1 and last_dot_pos > last_comma_pos and last_dot_pos != -1:
        # TÃ¼m virgÃ¼lleri kaldÄ±r, noktayÄ± virgÃ¼le Ã§evir
        amount_str = amount_str.replace(',', '').replace('.', ',')
    
    # DURUM 2: TÃ¼rk formatÄ± - son virgÃ¼l noktadan SONRA: 1.234,56
    # Nokta binlik ayÄ±rÄ±cÄ±, virgÃ¼l ondalÄ±k ayÄ±rÄ±cÄ± (zaten doÄŸru)
    elif comma_count >= 1 and last_comma_pos > last_dot_pos and last_comma_pos != -1:
        # Zaten TÃ¼rk formatÄ±, sadece binlik ayÄ±rÄ±cÄ±larÄ± dÃ¼zelt
        pass
    
    # DURUM 3: Tek nokta var: 1234.56 â†’ ABD formatÄ±
    elif dot_count == 1 and comma_count == 0:
        parts = amount_str.split('.')
        if len(parts) > 1 and len(parts[1]) <= 2:  # OndalÄ±k kÄ±sÄ±m 2 basamak veya daha az
            amount_str = amount_str.replace('.', ',')
    
    # DURUM 4: Tek virgÃ¼l var: 1234,56 â†’ TÃ¼rk formatÄ± (zaten doÄŸru)
    # HiÃ§bir ÅŸey yapma
    
    # Binlik ayÄ±rÄ±cÄ±larÄ± dÃ¼zelt
    if ',' in amount_str:
        parts = amount_str.split(',')
        integer_part = parts[0]
        decimal_part = parts[1] if len(parts) > 1 else '00'
        
        # Mevcut noktalardÄ± temizle
        integer_part = integer_part.replace('.', '')
        
        # Binlik gruplama yap (saÄŸdan sola)
        if len(integer_part) > 3:
            result = []
            for i, digit in enumerate(reversed(integer_part)):
                if i > 0 and i % 3 == 0:
                    result.append('.')
                result.append(digit)
            integer_part = ''.join(reversed(result))
        
        amount_str = f"{integer_part},{decimal_part}"
    
    return amount_str + currency

def extract_amount(text):
    """Tutar Ã§eker ve TÃ¼rk formatÄ±na Ã§evirir (GÃœVENLÄ° VERSÄ°YON)."""
    hdi_match = re.search(r'TOPLAM\s*PRÄ°M\s*[:\s]*([\d\.,]+)', text, re.IGNORECASE)
    if hdi_match: return normalize_amount_to_turkish(hdi_match.group(1))

    ethica_match = re.search(r'Ã–DENECEK\s*PRÄ°M\s*[:\s]*([\d\.,]+)', text, re.IGNORECASE)
    if ethica_match: return normalize_amount_to_turkish(ethica_match.group(1))

    quick_brut = re.search(r'BRÃœT\s*PRÄ°M\s*[:\s]*([\d\.,]+)', text, re.IGNORECASE)
    if quick_brut: return normalize_amount_to_turkish(quick_brut.group(1))

    dask_match = re.search(r'PoliÃ§e\s*Primi\s*[:\s]*([\d\.,]+)', text, re.IGNORECASE)
    if dask_match: return normalize_amount_to_turkish(dask_match.group(1))

    match = re.search(r'(?:Ã–DENECEK|GENEL\s*TOPLAM|TOPLAM|BRÃœT)\s*PRÄ°M[Ä°]?[:\s]*([\d\.,]+)\s*(?:TL|TRL)?', text, re.IGNORECASE)
    if match: return normalize_amount_to_turkish(match.group(1).strip())

    matches = re.findall(r'(\d{1,3}(?:[.,]\d{3})*[.,]\d{2})\s*TL', text)
    valid_amounts = []
    for m in matches:
        clean_val = m.replace(".", "").replace(",", ".")
        try:
            val = float(clean_val)
            if 10 < val < 50000000:
                valid_amounts.append(m)
        except: continue
    if valid_amounts:
        return normalize_amount_to_turkish(max(valid_amounts, key=lambda x: len(x)))

    return "0"

def get_text_robust(pdf_path):
    text = ""
    try:
        reader = PdfReader(pdf_path)
        for page in reader.pages[:2]:
            t = page.extract_text()
            if t: text += t + " "
    except: pass
    if len(text) < 50:
        try:
            with pdfplumber.open(pdf_path) as pdf:
                for page in pdf.pages[:2]:
                    t = page.extract_text()
                    if t: text += t + " "
        except: pass
    return text

# ==============================================================================
# ðŸ” 1. ADIM: GELÄ°ÅžMÄ°Åž TÃœR TESPÄ°TÄ°
# ==============================================================================
def identify_policy_type(pdf_path):
    """PDF iÃ§eriÄŸinden poliÃ§e tÃ¼rÃ¼nÃ¼ belirler (SADECE Ä°Ã‡ERÄ°KTEN)"""
    
    # PDF iÃ§eriÄŸini al - DoÄŸa iÃ§in daha fazla sayfa tara
    text_raw = ""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            # Ä°lk 5 sayfayÄ± tara (DoÄŸa bilgisi 2. veya 3. sayfada olabilir)
            # Bellek korumasÄ±: Her sayfa iÅŸlendikten sonra bellekten temizlenir
            for i, page in enumerate(pdf.pages[:5]):
                try:
                    t = page.extract_text()
                    if t: text_raw += t + " "
                except Exception as page_err:
                    if sys.stdout:
                        print(f"LOG: Sayfa {i+1} okunamadÄ± ({os.path.basename(pdf_path)}): {str(page_err)[:50]}")
    except Exception as e:
        if sys.stdout:
            print(f"LOG: PDF okuma hatasÄ± ({os.path.basename(pdf_path)}): {type(e).__name__}")
        text_raw = get_text_robust(pdf_path)
    
    # "ESKÄ° SÄ°GORTA ÅžÄ°RKETÄ°" satÄ±rlarÄ±nÄ± temizle (Ã–nemli!)
    text_cleaned = re.sub(r'ESKÄ°\s+SÄ°GORTA\s+ÅžÄ°RKET[Ä°I][:\s]+[A-ZÃ‡ÄžÄ°Ã–ÅžÃœa-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼\s]+', '', text_raw, flags=re.IGNORECASE)
    text_cleaned = re.sub(r'ESKÄ°\s+ÅžÄ°RKET[:\s]+[A-ZÃ‡ÄžÄ°Ã–ÅžÃœa-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼\s]+', '', text_cleaned, flags=re.IGNORECASE)
    text_cleaned = re.sub(r'Ã–NCEKÄ°\s+SÄ°GORTA[:\s]+[A-ZÃ‡ÄžÄ°Ã–ÅžÃœa-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼\s]+', '', text_cleaned, flags=re.IGNORECASE)
    text_cleaned = re.sub(r'Ã–NCEKÄ°\s+POLÄ°Ã‡E\s+ÅžÄ°RKET[Ä°I][:\s]+[A-ZÃ‡ÄžÄ°Ã–ÅžÃœa-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼\s]+', '', text_cleaned, flags=re.IGNORECASE)
    # ALLIANZ iÃ§in ek temizlik - "Ã–nceki Sigorta Åžirketi: ALLIANZ" veya "Ã–nceki SigortacÄ±" kalÄ±plarÄ±
    text_cleaned = re.sub(r'Ã–NCEKÄ°\s+SÄ°GORTACI[:\s]+[A-ZÃ‡ÄžÄ°Ã–ÅžÃœa-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼\s]+', '', text_cleaned, flags=re.IGNORECASE)
    text_cleaned = re.sub(r'Ã–nceki\s+Sigorta\s+Åžirketi[:\s]+[A-ZÃ‡ÄžÄ°Ã–ÅžÃœa-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼\s]+', '', text_cleaned, flags=re.IGNORECASE)
    
    # Ä°lk 30 satÄ±rda ara (Ãœst kÄ±sÄ±mda genelde asÄ±l ÅŸirket bilgisi var)
    lines_first = text_cleaned.split('\n')[:30]
    text_first_upper = ' '.join(lines_first).upper()
    text_upper = text_cleaned.upper()
    
    # =========================================================================
    # ÅžÄ°RKET TESPÄ°TÄ° - Ã–NCELÄ°K SIRASI Ã–NEMLÄ°!
    # 1) Ã–nce spesifik ÅŸirket adlarÄ± (ilk 30 satÄ±rda) - AXA, HDI, RAY vb.
    # 2) Sonra ALLIANZ (tÃ¼m metinde - footer'da olabilir)
    # =========================================================================
    
    # --- AXA ve diÄŸer spesifik ÅŸirketler (ilk 30 satÄ±rda) ---
    if "RAY SÄ°GORTA" in text_first_upper: return "TRAFÄ°K_RAY"
    if "HEPÄ°YÄ°" in text_first_upper or "HEPIYI" in text_first_upper: return "TRAFÄ°K_HEPÄ°YÄ°"
    if "ETHICA SÄ°GORTA" in text_first_upper or "ETHÄ°CA SÄ°GORTA" in text_first_upper: return "TRAFÄ°K_ETHICA"
    if "HDI SÄ°GORTA" in text_first_upper or "HDI SIGORTA" in text_first_upper or "0850 222 8 434" in text_first_upper:
        # HDI Yeni format kontrolÃ¼ - "BaÅŸlangÄ±Ã§-BitiÅŸ Tarihi" veya "Ad Soyad / Ãœnvan" varsa yeni format
        # Upper olmayan text'te ara (encoding problemi yÃ¼zÃ¼nden)
        text_first_raw = ' '.join(lines_first)
        if "BaÅŸlangÄ±Ã§-BitiÅŸ" in text_first_raw or "Ad Soyad / Ãœnvan" in text_first_raw:
            return "TRAFÄ°K_HDI_YENI"
        return "TRAFÄ°K_HDI"
    if "SOMPO" in text_first_upper: return "TRAFÄ°K_SOMPO"
    if "QUICK" in text_first_upper: return "TRAFÄ°K_QUICK"
    # DOÄžA SÄ°GORTA - PDF'teki 'Sigorta' kelimesi hem Ä°ngilizce I hem TÃ¼rkÃ§e Ä° olabilir
    if ("DOÄžA SÄ°GORTA" in text_first_upper or "DOGA SIGORTA" in text_first_upper or 
        "DOÄžA SIGORTA" in text_first_upper or "DOGA SÄ°GORTA" in text_first_upper): return "TRAFÄ°K_DOÄžA"
    
    # Bulamazsa tÃ¼m metne bak (ama temizlenmiÅŸ versiyonda)
    text_upper = text_cleaned.upper()

    # Åžirket belirleme (tÃ¼m metinde)
    if "RAY SÄ°GORTA" in text_upper: return "TRAFÄ°K_RAY"
    if "HEPÄ°YÄ°" in text_upper or "HEPIYI" in text_upper: return "TRAFÄ°K_HEPÄ°YÄ°"
    if "ETHICA SÄ°GORTA" in text_upper or "ETHÄ°CA SÄ°GORTA" in text_upper:
        if "TRAFÄ°K" in text_upper or "ZORUNLU MALÄ°" in text_upper: return "TRAFÄ°K_ETHICA"
    if "HDI SÄ°GORTA" in text_upper or "HDI SIGORTA" in text_upper or "0850 222 8 434" in text_upper:
        # HDI Yeni format kontrolÃ¼ - "BaÅŸlangÄ±Ã§-BitiÅŸ Tarihi" veya "Ad Soyad / Ãœnvan" varsa yeni format
        if "BaÅŸlangÄ±Ã§-BitiÅŸ" in text_cleaned or "Ad Soyad / Ãœnvan" in text_cleaned:
            return "TRAFÄ°K_HDI_YENI"
        return "TRAFÄ°K_HDI"
    if "SOMPO" in text_upper and ("TRAFÄ°K" in text_upper or "KARAYOLLARI" in text_upper): return "TRAFÄ°K_SOMPO"
    if "QUICK" in text_upper and ("TRAFÄ°K" in text_upper or "KARAYOLLARI" in text_upper): return "TRAFÄ°K_QUICK"
    # DOÄžA SÄ°GORTA - PDF'teki 'Sigorta' kelimesi hem Ä°ngilizce I hem TÃ¼rkÃ§e Ä° olabilir
    # Ã–nce ÅŸirket tespiti yap (poliÃ§e tÃ¼rÃ¼ kontrolÃ¼nden Ã–NCE!)
    if ("DOÄžA SÄ°GORTA" in text_upper or "DOGA SIGORTA" in text_upper or 
        "DOÄžA SIGORTA" in text_upper or "DOGA SÄ°GORTA" in text_upper):
        if "TRAFÄ°K" in text_upper or "KARAYOLLARI" in text_upper: return "TRAFÄ°K_DOÄžA"

    # --- ALLIANZ - TÃ¼m metinde kontrol et (ÅŸirket adÄ± footer'da olabilir) ---
    # Ã–NEMLÄ°: DiÄŸer spesifik ÅŸirketlerden SONRA kontrol edilmeli!
    if "ALLIANZ" in text_upper or "ALLÄ°ANZ" in text_upper or "ALLIANZSIGORTA" in text_upper:
        # KASKO vs TRAFÄ°K ayrÄ±mÄ± - aÃ§Ä±k kontrol ile
        # Ã–nce spesifik ALLIANZ KASKO kontrolÃ¼
        if "ALLIANZ KASKO" in text_upper or "GENÄ°ÅžLETÄ°LMÄ°Åž KASKO" in text_upper:
            return "KASKO_ALLIANZ"
        # Sonra TRAFÄ°K kontrolÃ¼
        if "TRAFÄ°K" in text_upper or "ZORUNLU MALÄ°" in text_upper or "KARAYOLLARI MOTORLU" in text_upper:
            return "TRAFÄ°K_ALLIANZ"
        # Genel KASKO kontrolÃ¼ (TRAFÄ°K iÃ§ermeyen)
        if "KASKO" in text_upper and "TRAFÄ°K" not in text_upper:
            return "KASKO_ALLIANZ"

    # PoliÃ§e tÃ¼rÃ¼ belirleme (iÃ§erikten) - ÅžÄ°RKET TESPÄ°TÄ°NDEN SONRA!
    # Ã–NCELÄ°K SIRASI Ã–NEMLÄ°! Ã–nce spesifik, sonra genel kontroller
    
    # 1. Ã‡ok spesifik tÃ¼rler Ã¶nce
    if "Ä°ÅžYERÄ°M" in text_upper or "ISYERIM" in text_upper: return "Ä°ÅžYERÄ°"
    if "NAKLÄ°YAT" in text_upper or "EMTÄ°A" in text_upper: return "NAKLÄ°YAT"
    
    # 2. SEYAHAT - Sadece Ã§ok spesifik kontroller
    if "SEYAHAT SÄ°GORTASI" in text_upper: return "SEYAHAT"
    if "SEYAHAT SAÄžLIK SÄ°GORTASI" in text_upper: return "SEYAHAT"
    
    # 3. EVÄ°M PAKET - DASK'tan Ã¶nce kontrol et
    if "EVÄ°M PAKET" in text_upper: return "EVÄ°M"
    
    # 4. DASK - "ZORUNLU DEPREM SÄ°GORTASI" spesifik olarak ara
    if "ZORUNLU DEPREM" in text_upper: return "DASK"
    
    # 5. SaÄŸlÄ±k - Spesifik kontroller
    if "SAÄžLIÄžIM" in text_upper or "TAMAMLAYICI SAÄžLIK" in text_upper: return "SAÄžLIK"
    if "SAÄžLIK SÄ°GORTASI" in text_upper or "SAÄžLIK POLÄ°Ã‡ESÄ°" in text_upper: return "SAÄžLIK"
    
    # 6. KASKO - TRAFÄ°K kontrolÃ¼nden Ã–NCE (Ã§Ã¼nkÃ¼ bazÄ± trafik poliÃ§elerinde "kasko" kelimesi geÃ§ebilir)
    if "KASKO POLÄ°Ã‡ESÄ°" in text_upper or "KASKO SÄ°GORTASI" in text_upper: return "KASKO"
    
    # 7. TRAFÄ°K kontrolleri
    if "TRAFÄ°K SÄ°GORTASI" in text_upper or "ZORUNLU MALÄ°" in text_upper: return "TRAFÄ°K"
    if "KARAYOLLARI MOTORLU" in text_upper: return "TRAFÄ°K"
    
    # 8. KASKO - Genel kontrol (TRAFÄ°K iÃ§ermeyen)
    if "KASKO" in text_upper and "TRAFÄ°K" not in text_upper: return "KASKO"
    
    # 9. EVÄ°M - Genel (KONUT + YANGIN)
    if "KONUT" in text_upper and "YANGIN" in text_upper: return "EVÄ°M"
    
    # 10. DASK - Sadece "DASK" kelimesi geÃ§iyorsa (en son kontrol)
    if "DASK" in text_upper: return "DASK"
    
    # 11. Genel TRAFÄ°K - SAÄžLIK'tan Ã¶nce
    if "TRAFÄ°K" in text_upper: return "TRAFÄ°K"
    
    # 12. SAÄžLIK - Ã‡ok genel olduÄŸu iÃ§in EN SON kontrol (sadece spesifik)
    if "Ã–ZEL SAÄžLIK" in text_upper: return "SAÄžLIK"

    return "BILINMIYOR"

# ==============================================================================
# âš™ï¸ PARSING MOTORLARI (REGEX)
# ==============================================================================

def process_hdi_trafik(pdf_path, filename):
    full_text = ""
    lines = []
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages[:2]:
                text = page.extract_text()
                if text:
                    full_text += text + " "
                    lines.extend(text.split('\n'))
    except Exception as e:
        if sys.stdout:
            print(f"LOG: HDI PDF okuma hatasÄ± ({filename}): {type(e).__name__}")
        return None
    
    if not full_text.strip():
        if sys.stdout:
            print(f"LOG: HDI PDF boÅŸ iÃ§erik ({filename})")
        return None
    
    tr_map = {ord('i'): 'Ä°', ord('Ä±'): 'I', ord('ÄŸ'): 'Äž', ord('Ã¼'): 'Ãœ', ord('ÅŸ'): 'Åž', ord('Ã¶'): 'Ã–', ord('Ã§'): 'Ã‡'}
    content = clean_text(full_text).translate(tr_map).upper()
    insured_name = "-"
    for i, line in enumerate(lines):
        line_clean = line.strip().translate(tr_map).upper()
        if "ADI SOYADI" in line_clean and "UNVANI" in line_clean:
            candidate = line_clean.replace("ADI SOYADI", "").replace("UNVANI", "").replace("/", "").replace(":", "").strip()
            if len(candidate) > 3: insured_name = candidate
            elif i + 1 < len(lines):
                next_line = lines[i+1].strip().translate(tr_map).upper()
                invalid_starts = ["T.C.", "ADRES", "NO:", "MERKEZ", "POLÄ°Ã‡E", "PLAKA", "MÃœÅžTERÄ°", "VERGÄ°"]
                if len(next_line) > 3 and not any(next_line.startswith(x) for x in invalid_starts): insured_name = next_line
            break
    if insured_name != "-":
        parts = insured_name.split()
        clean_parts = [part for part in parts if not any(char.isdigit() for char in part) and "/" not in part and ":" not in part]
        insured_name = " ".join(clean_parts) if clean_parts else insured_name.split(" NO")[0]

    amount = "0"
    search_keywords = ["TOPLAM PRÄ°M", "TOPLAM PRIM", "Ã–DENECEK", "GENEL TOPLAM"]
    start_index = -1
    for kw in search_keywords:
        idx = content.find(kw)
        if idx != -1:
            start_index = idx
            break
    if start_index != -1:
        search_area = content[start_index : start_index + 100]
        money_match = re.search(r'(\d{1,3}(?:\.\d{3})*,\d{2})', search_area)
        if money_match: amount = normalize_amount_to_turkish(money_match.group(1))
    if amount == "0":
        all_matches = re.findall(r'(\d{1,3}(?:\.\d{3})*,\d{2})', content)
        if all_matches: amount = normalize_amount_to_turkish(all_matches[-1])

    date = "-"
    date_match = re.search(r'BAÅžLANGIÃ‡\s*TARÄ°HÄ°\s*[:\s]*(\d{2}/\d{2}/\d{4})', content)
    if date_match: date = date_match.group(1)
    policy_no = "-"
    pol_match = re.search(r'POLÄ°Ã‡E\s*NO\s*[:\s]*(\d{10,}[-\d]*)', content)
    if pol_match: policy_no = pol_match.group(1)
    cust_no = "-"
    cust_match = re.search(r'MÃœÅžTERÄ°\s*NO\s*[:\.\s]*(\d{6,})', content)
    if cust_match: cust_no = cust_match.group(1)
    plate = "-"
    pl_match = re.search(r'PLAKA\s*NO.*?\s*(\d{2,3}\s*[A-Z]{1,4}\s*\d{2,5})', content)
    if pl_match: plate = pl_match.group(1).replace(" ", "")
    brand = "-"
    brand_match = re.search(r'MODEL\s*/\s*MARKA\s*[:\s]*\d{4}\s+([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ\s\-]+)', content)
    if brand_match: brand = brand_match.group(1).strip().split(" ")[0]
    return {"SÄ°GORTALI": insured_name, "TARÄ°H": date, "MÃœÅžTERÄ° NO": cust_no, "POLÄ°Ã‡E NO": policy_no, "TÃœR": "TRAFÄ°K", "PLAKA": plate, "MARKA": brand, "TUTAR": amount, "ÅžÄ°RKET": "HDI"}

def hdi_yeni_police(pdf_path, filename):
    """HDI Yeni Format Trafik PoliÃ§esi (2026 format)"""
    full_text = ""
    lines = []
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages[:2]:
                text = page.extract_text()
                if text:
                    full_text += text + " "
                    lines.extend(text.split('\n'))
    except: return None
    
    tr_map = {ord('i'): 'Ä°', ord('Ä±'): 'I', ord('ÄŸ'): 'Äž', ord('Ã¼'): 'Ãœ', ord('ÅŸ'): 'Åž', ord('Ã¶'): 'Ã–', ord('Ã§'): 'Ã‡'}
    content = clean_text(full_text).translate(tr_map).upper()
    
    # SigortalÄ± AdÄ± - Yeni formatta "Ad Soyad / Ãœnvan ISIM SOYISIM"
    insured_name = "-"
    for i, line in enumerate(lines):
        line_clean = line.strip().translate(tr_map).upper()
        # "Ad Soyad / Ãœnvan" baÅŸlÄ±ÄŸÄ±nÄ± bul ve aynÄ± satÄ±rda isim var
        if "AD SOYAD" in line_clean and ("/" in line_clean or "UNVAN" in line_clean):
            # BaÅŸlÄ±k sonrasÄ± kÄ±smÄ± al
            parts = line_clean.split("UNVAN")
            if len(parts) > 1:
                candidate = parts[1].strip()
            else:
                # "/" sonrasÄ± al
                if "/" in line_clean:
                    candidate = line_clean.split("/")[-1].strip()
                else:
                    candidate = line_clean.replace("AD SOYAD", "").strip()
            
            if len(candidate) > 3 and "SIGORTA" not in candidate and "KIMLIK" not in candidate:
                insured_name = candidate
                break
    
    if insured_name != "-":
        # "ÃœNVAN" kelimesini temizle
        insured_name = insured_name.replace("ÃœNVAN", "").strip()
        parts = insured_name.split()
        clean_parts = [part for part in parts if not any(char.isdigit() for char in part) and "/" not in part]
        insured_name = " ".join(clean_parts) if clean_parts else insured_name
    
    # Tutar - "Toplam Ã–denecek Prim"
    amount = "0"
    amount_match = re.search(r'TOPLAM\s+Ã–DENECEK\s+PRÄ°M\s+([\d\.\,]+)\s*TL', content)
    if amount_match:
        amount = normalize_amount_to_turkish(amount_match.group(1))
    else:
        # Alternatif: "TOPLAM PRÄ°M" ara
        search_keywords = ["TOPLAM PRÄ°M", "TOPLAM PRIM", "Ã–DENECEK"]
        for kw in search_keywords:
            idx = content.find(kw)
            if idx != -1:
                search_area = content[idx : idx + 100]
                money_match = re.search(r'([\d]{1,3}(?:\.[\d]{3})*,[\d]{2})', search_area)
                if money_match:
                    amount = normalize_amount_to_turkish(money_match.group(1))
                    break
    
    # Tarih - "BaÅŸlangÄ±Ã§-BitiÅŸ Tarihi 06/01/2026-06/01/2027"
    date = "-"
    date_match = re.search(r'BAÅžLANGIÃ‡[\-\s]*BÄ°TÄ°Åž\s*TARÄ°HÄ°\s+([\d]{2}/[\d]{2}/[\d]{4})', content)
    if not date_match:
        # Alternatif: "BASLANGIC-BITIS TARIHI" (TÃ¼rkÃ§e karakter olmadan)
        date_match = re.search(r'BA[SÅž]LANGI[Ã‡C][\-\s]*B[Ä°I]T[Ä°I][SÅž]\s*TAR[Ä°I]H[Ä°I]\s+([\d]{2}/[\d]{2}/[\d]{4})', content)
    if date_match:
        date = date_match.group(1)
    
    # PoliÃ§e No
    policy_no = "-"
    pol_match = re.search(r'POLÄ°Ã‡E\s*NO\s+([\d]{10,})', content)
    if pol_match:
        policy_no = pol_match.group(1)
    
    # MÃ¼ÅŸteri No - HDI Yeni formatta mÃ¼ÅŸteri numarasÄ± yok (sadece maskeli T.C. Kimlik var)
    cust_no = "-"
    
    # Plaka
    plate = "-"
    pl_match = re.search(r'PLAKA\s*NO\s+([\d]{2}[A-Z]{1,4}[\d]{2,5})', content)
    if pl_match:
        plate = pl_match.group(1)
    
    # Marka - "Marka CHERY" formatÄ±nda
    brand = "-"
    brand_match = re.search(r'MARKA\s+([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ]+)', content)
    if not brand_match:
        # Case-insensitive arama
        brand_match = re.search(r'(?:MARKA|Marka)\s+([A-ZÃ‡ÄžÄ°Ã–ÅžÃœa-z]+)', full_text)
    if brand_match:
        brand = brand_match.group(1).strip().upper()
    
    return {
        "SÄ°GORTALI": insured_name,
        "TARÄ°H": date,
        "MÃœÅžTERÄ° NO": cust_no,
        "POLÄ°Ã‡E NO": policy_no,
        "TÃœR": "TRAFÄ°K",
        "PLAKA": plate,
        "MARKA": brand,
        "TUTAR": amount,
        "ÅžÄ°RKET": "HDI"
    }

def process_ethica_trafik(pdf_path, filename):
    text = ""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages[:2]: text += page.extract_text() + " "
    except: return None
    tr_map = {ord('i'): 'Ä°', ord('Ä±'): 'I', ord('ÄŸ'): 'Äž', ord('Ã¼'): 'Ãœ', ord('ÅŸ'): 'Åž', ord('Ã¶'): 'Ã–', ord('Ã§'): 'Ã‡'}
    content = clean_text(text).translate(tr_map).upper()
    insured_name = "-"
    name_match = re.search(r'SÄ°GORTALININ\s*ADI\s*SOYADI.*?:[:\s]*([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ\s\.]+?)(?=\s*(?:SÄ°GORTALININ\s*ADRESÄ°|T\.C\.|ADRES))', content)
    if name_match: insured_name = name_match.group(1).strip()
    date = "-"
    date_match = re.search(r'BAÅžLANGIÃ‡\s*TARÄ°HÄ°\s*[:\s]*(\d{2}/\d{2}/\d{4})', content)
    if date_match: date = date_match.group(1)
    policy_no = "-"
    pol_match = re.search(r'POLÄ°Ã‡E\s*NO\s*[:\s]*(\d{8,})', content)
    if pol_match: policy_no = pol_match.group(1)
    cust_no = "-"
    cust_match = re.search(r'MÃœÅžTERÄ°\s*NO\s*[:\s]*(\d{6,})', content)
    if cust_match: cust_no = cust_match.group(1)
    plate = "-"
    pl_match = re.search(r'PLAKA\s*NO\s*[:\s]*(\d{2,3}\s*[A-Z]{1,4}\s*\d{2,5})', content)
    if pl_match: plate = pl_match.group(1).replace(" ", "")
    brand = "-"
    brand_match = re.search(r'(?<!TÄ°PÄ°)\s+MARKA\s*[:\s]*([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ]+)', content)
    if brand_match: brand = brand_match.group(1).strip()
    else:
        brand_alt = re.search(r'MARKA\s*[:\s]*([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ]+?)(?=\s+MODEL)', content)
        if brand_alt: brand = brand_alt.group(1).strip()
    amount = "0"
    amount_match = re.search(r'Ã–DENECEK\s*PRÄ°M\s*[:\s]*([\d\.,]+)', content)
    if amount_match: amount = normalize_amount_to_turkish(amount_match.group(1))
    else: amount = extract_amount(content)
    return {"SÄ°GORTALI": insured_name, "TARÄ°H": date, "MÃœÅžTERÄ° NO": cust_no, "POLÄ°Ã‡E NO": policy_no, "TÃœR": "TRAFÄ°K", "PLAKA": plate, "MARKA": brand, "TUTAR": amount, "ÅžÄ°RKET": "ETHÄ°CA"}

def process_quick_trafik(pdf_path, filename):
    text = ""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages[:3]:
                t = page.extract_text()
                if t: text += t + "\n"
    except: return None
    tr_map = {ord('i'): 'Ä°', ord('Ä±'): 'I', ord('ÄŸ'): 'Äž', ord('Ã¼'): 'Ãœ', ord('ÅŸ'): 'Åž', ord('Ã¶'): 'Ã–', ord('Ã§'): 'Ã‡'}
    content = clean_text(text).translate(tr_map).upper()
    insured_name = "-"
    name_match = re.search(r'SÄ°GORTALI.*?(?:ADI/ÃœNVANI)\s*[:\s]*([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ\s\.]+?)(?=\s*(?:ADRESÄ°|TELEFON|E-POSTA))', content)
    if name_match: insured_name = name_match.group(1).strip()
    else:
        name_alt = re.search(r'SÄ°GORTALI\s*[:\s]*([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ\s\.]+?)(?=\s*(?:ADRESÄ°))', content)
        if name_alt: insured_name = name_alt.group(1).strip()
    date = "-"
    date_match = re.search(r'POLÄ°Ã‡E\s*BAÅžLANGIÃ‡\s*TARÄ°HÄ°\s*[:\s]*(\d{2}/\d{2}/\d{4})', content)
    if date_match: date = date_match.group(1)
    policy_no = "-"
    pol_match = re.search(r'POLÄ°Ã‡E\s*NO\s*[:\s]*(\d{10,})', content)
    if pol_match: policy_no = pol_match.group(1)
    plate = "-"
    pl_match = re.search(r'PLAKA\s*NO.*?\s*(\d{2}\s*[A-Z]{1,4}\s*\d{2,5})', content)
    if pl_match: plate = pl_match.group(1).replace(" ", "")
    amount = extract_amount(content)
    
    # Ã‡APA YÃ–NTEMÄ°
    brand = "-"
    raw_values = re.findall(r':\s*([^\n]+)', text)
    clean_values = []
    for v in raw_values:
        v_clean = v.strip().translate(tr_map).upper()
        if len(v_clean) > 1: clean_values.append(v_clean)
    year_index = -1
    for i, val in enumerate(clean_values):
        if val.isdigit() and len(val) == 4 and val.startswith(("20", "19")):
            if "/" not in val and "." not in val:
                year_index = i
                break
    if year_index != -1:
        if year_index > 0:
            prev_val = clean_values[year_index - 1]
            blacklist = ["OTOMOBÄ°L", "KAMYONET", "HUSUSÄ°", "TÄ°CARÄ°", "BENZÄ°N", "DÄ°ZEL", "MANUEL", "OTOMATÄ°K", "YOK", "HAYIR", "EVET"]
            if not any(b in prev_val for b in blacklist) and not prev_val.isdigit():
                brand = prev_val
        if brand == "-" or len(brand) < 2:
            if year_index + 1 < len(clean_values):
                next_val = clean_values[year_index + 1]
                brand = next_val.split()[0]
    if len(brand) > 20 or (any(c.isdigit() for c in brand) and " " not in brand): brand = "-"

    return {"SÄ°GORTALI": insured_name, "TARÄ°H": date, "MÃœÅžTERÄ° NO": "-", "POLÄ°Ã‡E NO": policy_no, "TÃœR": "TRAFÄ°K", "PLAKA": plate, "MARKA": brand, "TUTAR": amount, "ÅžÄ°RKET": "QUICK"}

def process_sompo_trafik(pdf_path, filename):
    text = ""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            if len(pdf.pages) > 0: text += pdf.pages[0].extract_text() + " "
            if len(pdf.pages) > 1: text += pdf.pages[1].extract_text() + " "
    except Exception as e:
        if sys.stdout:
            print(f"LOG: SOMPO PDF okuma hatasÄ± ({filename}): {type(e).__name__}")
        return None
    
    if not text.strip():
        if sys.stdout:
            print(f"LOG: SOMPO PDF boÅŸ iÃ§erik ({filename})")
        return None
    content = clean_text(text)
    insured_name = "-"
    name_match = re.search(r'ADI\s*SOYADI\s*/\s*ÃœNVANI.*?[:]\s*([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ\s\.]+?)(?=\s*(?:TC\s*KÄ°MLÄ°K|ADRESÄ°|ADRES))', content, re.IGNORECASE)
    if name_match: insured_name = name_match.group(1).strip()
    else:
        name_alt = re.search(r'SÄ°GORTALI.*?[:\s]([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ\s]{5,30})', content)
        if name_alt: insured_name = name_alt.group(1).strip()
    date = "-"
    date_matches = re.findall(r'(\d{2}/\d{2}/\d{4})', content)
    if date_matches: date = date_matches[0]
    policy_no = "-"
    pol_match = re.search(r'\b(3\d{14})\b', content)
    if pol_match: policy_no = pol_match.group(1)
    else:
        pol_lbl = re.search(r'POLÄ°Ã‡E\s*NO\s*[:\s]*(\d{10,})', content, re.IGNORECASE)
        if pol_lbl: policy_no = pol_lbl.group(1)
    cust_no = "-"
    cust_match = re.search(r'\b(8\d{9})\b', content)
    if cust_match: cust_no = cust_match.group(1)
    else:
        digits_10 = re.findall(r'\b([1-9]\d{9})\b', content)
        for num in digits_10:
            if not num.startswith("5"): cust_no = num; break
    plate = "-"
    pl_match = re.search(r'Plaka\s*No\s*[:\s]*([0-9]{2}\s*[A-Z]{1,4}\s*\d{2,5})', content, re.IGNORECASE)
    if pl_match: plate = pl_match.group(1).replace(" ", "")
    brand = "-"
    egm_match = re.search(r'EGM\s*Marka\s*Bilgisi\s*[:\s]*([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ\s\(\)\-]+?)(?=\s*(?:EGM|Model|Trafik))', content, re.IGNORECASE)
    if egm_match: brand = egm_match.group(1).strip()
    if brand == "-" or len(brand) < 2:
        br_match = re.search(r'Marka/Tip\s*[:\s]*([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ0-9\s\(\)\-\.]+?)(?=\s*(?:KullanÄ±m|Model|Trafik|EGM|Plaka))', content, re.IGNORECASE)
        if br_match: brand = br_match.group(1).strip().split(" ")[0]
    amount = extract_amount(content)
    return {"SÄ°GORTALI": insured_name, "TARÄ°H": date, "MÃœÅžTERÄ° NO": cust_no, "POLÄ°Ã‡E NO": policy_no, "TÃœR": "TRAFÄ°K", "PLAKA": plate, "MARKA": brand, "TUTAR": amount, "ÅžÄ°RKET": "SOMPO"}

def process_doga_trafik(pdf_path, filename):
    full_text = ""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages[:5]:
                t = page.extract_text()
                if t: full_text += t + " "
    except Exception as e:
        if sys.stdout:
            print(f"LOG: DOÄžA PDF okuma hatasÄ± ({filename}): {type(e).__name__}")
    
    if not full_text.strip():
        if sys.stdout:
            print(f"LOG: DOÄžA PDF boÅŸ iÃ§erik ({filename})")
        return None
    tr_map = {ord('i'): 'Ä°', ord('Ä±'): 'I', ord('ÄŸ'): 'Äž', ord('Ã¼'): 'Ãœ', ord('ÅŸ'): 'Åž', ord('Ã¶'): 'Ã–', ord('Ã§'): 'Ã‡'}
    content = clean_text(full_text).translate(tr_map).upper()
    insured_name = "-"
    try:
        with pdfplumber.open(pdf_path) as pdf:
            first_page_lines = pdf.pages[0].extract_text().split('\n')
            for i, line in enumerate(first_page_lines):
                line_clean = line.strip().translate(tr_map).upper()
                if line_clean == "SÄ°GORTALI" or line_clean == "SIGORTALI":
                    if i + 1 < len(first_page_lines):
                        candidate = first_page_lines[i+1].strip().translate(tr_map).upper()
                        invalid_words = ["MAH", "MAHALLESÄ°", "CAD", "SOK", "SK", "NO:", "AP", "DAÄ°RE"]
                        if len(candidate) > 3 and not any(w in candidate.split() for w in invalid_words):
                            insured_name = candidate; break
    except: pass
    if insured_name == "-":
        name_match = re.search(r'SÄ°GORTALI\s+([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ\s]{3,40}?)(?=\s+(?:MAH\.|MAHALLESÄ°|CD\.|CADDE|SK\.|SOKAK|AP\.|NO:))', content)
        if name_match: insured_name = name_match.group(1).strip()
    plate = "-"
    pl_match = re.search(r'PLAKA\s*[:\s]*(\d{2,3}\s*[A-Z]{1,4}\s*\d{2,5})', content)
    if not pl_match: pl_match = re.search(r'PLAKA\s+(\d{2,3}\s*[A-Z]{1,4}\s*\d{2,5})', content)
    if pl_match: plate = pl_match.group(1).replace(" ", "")
    policy_no = "-"
    prod_match = re.search(r'ÃœRÃœN\s*NO\s*[:\/]*\s*(\d{8,})', content)
    if prod_match: policy_no = prod_match.group(1)
    if policy_no == "-":
        pol_match = re.search(r'POLÄ°Ã‡E\s*NO\s*[:\s]*(\d{8,})', content)
        if pol_match: policy_no = pol_match.group(1)
    date = "-"
    date_match = re.search(r'(?:BAÅžLAMA|BAÅžLANGIÃ‡)\s*TARÄ°HÄ°\s*[:\s]*(\d{2}[/.-]\d{2}[/.-]\d{4})', content)
    if not date_match: date_match = re.search(r'(\d{2}\.\d{2}\.\d{4})', content)
    if date_match: date = date_match.group(1).replace(".", "/").replace("-", "/")
    cust_no = "-"
    cust_match = re.search(r'MÃœÅžTERÄ°\s*NO\s*[:\s]*(\d{6,15})', content)
    if cust_match: cust_no = cust_match.group(1)
    brand = "-"
    egm_match = re.search(r'EGM\s*ARAÃ‡\s*BÄ°LGÄ°LERÄ°.*?MARKA\s*[:\s]*([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ]+)', content)
    if not egm_match: egm_match = re.search(r'MARKA\s*[:\s]*([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ\s]+?)(?=\s+MOTOR)', content)
    if egm_match: brand = egm_match.group(1).strip()
    amount = extract_amount(content)
    return {"SÄ°GORTALI": insured_name, "TARÄ°H": date, "MÃœÅžTERÄ° NO": cust_no, "POLÄ°Ã‡E NO": policy_no, "TÃœR": "TRAFÄ°K", "PLAKA": plate, "MARKA": brand, "TUTAR": amount, "ÅžÄ°RKET": "DOÄžA"}

def process_hepiyi_trafik(pdf_path, filename):
    text = ""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages[:2]: text += page.extract_text() + " "
    except: return None
    tr_map = {ord('i'): 'Ä°', ord('Ä±'): 'I', ord('ÄŸ'): 'Äž', ord('Ã¼'): 'Ãœ', ord('ÅŸ'): 'Åž', ord('Ã¶'): 'Ã–', ord('Ã§'): 'Ã‡'}
    content = clean_text(text).translate(tr_map).upper()
    insured_name = "-"
    name_match = re.search(r'SÄ°GORTALI ADI SOYADI/ÃœNVANI\s*[:\s]*([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ\s\.]+?)(?=\s*(?:KÄ°MLÄ°K|SÄ°GORTALI ADRESÄ°|T\.C\.))', content)
    if name_match: insured_name = name_match.group(1).strip()
    plate = "-"
    pl_match = re.search(r'PLAKA\s*[:\s]*(\d{2,3}\s*[A-Z]{1,4}\s*\d{2,5})', content)
    if pl_match: plate = pl_match.group(1).replace(" ", "")
    brand = "-"
    br_match = re.search(r'MARKA\s*[:\s]*([A-Z0-9\s\-\.]+?)(?=\s*MOTOR|TÄ°PÄ°)', content)
    if br_match: brand = br_match.group(1).strip()
    date = "-"
    date_triplet = re.search(r'(\d{2}/\d{2}/\d{4})\s+(\d{2}/\d{2}/\d{4})\s+(\d{2}/\d{2}/\d{4})', content)
    if date_triplet: date = date_triplet.group(2)
    else:
        d_match = re.search(r'BAÅžLAMA TARÄ°HÄ°.*?(\d{2}/\d{2}/\d{4})', content)
        if d_match: date = d_match.group(1)
    policy_no = "-"
    p_match = re.search(r'POLÄ°Ã‡E NO\s*(\d{10,})', content)
    if not p_match: p_match = re.search(r'POLÄ°Ã‡E NO.*?(\d{10,})', content)
    if p_match: policy_no = p_match.group(1)
    cust_no = "-"
    c_match = re.search(r'MÃœÅžTERÄ° NO\.\s*(\d+)', content)
    if not c_match: c_match = re.search(r'MÃœÅžTERÄ° NO.*?(\d{6,})', content)
    if c_match: cust_no = c_match.group(1)
    amount = "0"
    amt_match = re.search(r'BRÃœT PRÄ°M\s*([\d\.,]+)', content)
    if amt_match: amount = normalize_amount_to_turkish(amt_match.group(1))
    else: amount = extract_amount(content)
    return {"SÄ°GORTALI": insured_name, "TARÄ°H": date, "MÃœÅžTERÄ° NO": cust_no, "POLÄ°Ã‡E NO": policy_no, "TÃœR": "TRAFÄ°K", "PLAKA": plate, "MARKA": brand, "TUTAR": amount, "ÅžÄ°RKET": "HEPÄ°YÄ°"}

def process_ray_trafik(pdf_path, filename):
    text = ""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages[:3]:
                extracted = page.extract_text()
                if extracted: text += extracted + " "
    except: return None
    tr_map = {ord('i'): 'Ä°', ord('Ä±'): 'I', ord('ÄŸ'): 'Äž', ord('Ã¼'): 'Ãœ', ord('ÅŸ'): 'Åž', ord('Ã¶'): 'Ã–', ord('Ã§'): 'Ã‡'}
    content = clean_text(text).translate(tr_map).upper()
    insured_name = "-"
    stop_words = r"(?:T\.C\.|TC\.|KÄ°MLÄ°K|ADRES|SÄ°GORTA|VERGÄ°|MÃœÅžTERÄ°|PLAKA|ZEYL)"
    name_match = re.search(r'AD\s*SOYAD\/?Ãœ?N?V?A?N?.*?[:]\s*([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ\s\.]+?)(?=\s*' + stop_words + r'|:)', content)
    if name_match:
        raw_name = name_match.group(1).strip()
        unwanted = ["T.C.", "KÄ°MLÄ°K", "ADRES", "SÄ°GORTA", "VERGÄ°"]
        for word in unwanted:
            if word in raw_name: raw_name = raw_name.split(word)[0].strip()
        if raw_name.endswith("ADRESÄ°"): raw_name = raw_name.replace("ADRESÄ°", "").strip()
        if len(raw_name) > 2: insured_name = raw_name
    if insured_name == "-":
        alt_match = re.search(r'AD\s*SOYAD\/ÃœNVAN\s*[:]\s*([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ\s\.]+)', content)
        if alt_match: insured_name = alt_match.group(1).strip()
    brand = "-"
    br_match = re.search(r'MARKASI\s*[:]\s*([A-Z0-9\s\.\-]+?)(?=\s*TÄ°PÄ°)', content)
    if br_match: brand = br_match.group(1).strip()
    if brand == "-" or len(brand) < 2:
        egm_match = re.search(r'EGM\s*MARKA\s*[:]\s*([A-Z0-9\s\.\-]+?)(?=\s*EGM)', content)
        if egm_match: brand = egm_match.group(1).strip()
    policy_no = "-"
    pol_match = re.search(r'POLÄ°Ã‡E.*?YENÄ°LEME.*?NO\s*[:\s]*([\d\/]+)', content)
    if pol_match: policy_no = pol_match.group(1)
    cust_no = "-"
    c_match = re.search(r'SÄ°GORTALI.*?M\.?NO.*?[:]\s*(\d+)', content)
    if c_match: cust_no = c_match.group(1)
    plate = "-"
    pl_match = re.search(r'PLAKA\s*NO\s*[:]\s*([\d]{2,3}\s*[A-Z]{1,4}\s*[\d]{2,5})', content)
    if pl_match: plate = pl_match.group(1).replace(" ", "")
    date = "-"
    date_match = re.search(r'BAÅžLANGIÃ‡\s*TARÄ°HÄ°\s*[:\s]*(\d{2}/\d{2}/\d{4})', content)
    if date_match: date = date_match.group(1)
    amount = "0"
    amt_match = re.search(r'TOPLAM\s*BRÃœT\s*PR[Ä°I]M\s*[:\s]*([\d\.,]+)', content)
    if amt_match: amount = normalize_amount_to_turkish(amt_match.group(1))
    else:
        amt_alt = re.search(r'BRÃœT\s*PR[Ä°I]M\s*[:\s]*([\d\.,]+)', content)
        if amt_alt: amount = normalize_amount_to_turkish(amt_alt.group(1))
        else: amount = extract_amount(content)
    return {"SÄ°GORTALI": insured_name, "TARÄ°H": date, "MÃœÅžTERÄ° NO": cust_no, "POLÄ°Ã‡E NO": policy_no, "TÃœR": "TRAFÄ°K", "PLAKA": plate, "MARKA": brand, "TUTAR": amount, "ÅžÄ°RKET": "RAY"}

def process_allianz_trafik(pdf_path, filename):
    """Allianz Trafik PoliÃ§esi - KarayollarÄ± Motorlu AraÃ§lar Zorunlu Mali Sorumluluk"""
    full_text = ""
    lines = []
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages[:3]:
                text = page.extract_text()
                if text:
                    full_text += text + " "
                    lines.extend(text.split('\n'))
    except Exception as e:
        if sys.stdout:
            print(f"LOG: ALLIANZ TRAFÄ°K PDF okuma hatasÄ± ({filename}): {type(e).__name__}")
        return None
    
    if not full_text.strip():
        if sys.stdout:
            print(f"LOG: ALLIANZ TRAFÄ°K PDF boÅŸ iÃ§erik ({filename})")
        return None
    
    tr_map = {ord('i'): 'Ä°', ord('Ä±'): 'I', ord('ÄŸ'): 'Äž', ord('Ã¼'): 'Ãœ', ord('ÅŸ'): 'Åž', ord('Ã¶'): 'Ã–', ord('Ã§'): 'Ã‡'}
    content = clean_text(full_text).translate(tr_map).upper()
    content_raw = clean_text(full_text)
    
    # SigortalÄ± AdÄ± - "AdÄ± SoyadÄ± : Ä°SÄ°M SOYÄ°SÄ°M"
    insured_name = "-"
    for line in lines:
        if "AdÄ± SoyadÄ±" in line and ":" in line:
            parts = line.split(":")
            if len(parts) > 1:
                candidate = parts[1].strip()
                # Sadece harf ve boÅŸluk iÃ§eren kÄ±smÄ± al
                name_parts = []
                for word in candidate.split():
                    if word.isalpha() or word.replace(".", "").isalpha():
                        name_parts.append(word)
                    elif name_parts:  # Ä°simden sonra numara gelirse dur
                        break
                if name_parts:
                    insured_name = " ".join(name_parts)
                    break
    
    # PoliÃ§e No - "PoliÃ§e No : 0001-0210-63424647"
    policy_no = "-"
    pol_match = re.search(r'PoliÃ§e\s*No\s*[:\s]*(\d{4}-\d{4}-\d{8})', content_raw, re.IGNORECASE)
    if pol_match:
        policy_no = pol_match.group(1)
    else:
        pol_match2 = re.search(r'POLÄ°Ã‡E\s*NO\s*[:\s]*([\d\-]{10,})', content)
        if pol_match2:
            policy_no = pol_match2.group(1)
    
    # BaÅŸlangÄ±Ã§ Tarihi - "BaÅŸlangÄ±Ã§ Tarihi : 20/01/2026 12:00"
    date = "-"
    date_match = re.search(r'BaÅŸlangÄ±Ã§\s*Tarihi\s*[:\s]*(\d{2}/\d{2}/\d{4})', content_raw, re.IGNORECASE)
    if date_match:
        date = date_match.group(1)
    
    # Plaka No - "Plaka No : 66 LL 208"
    plate = "-"
    pl_match = re.search(r'Plaka\s*No\s*[:\s]*(\d{2,3}\s*[A-ZÃ‡ÄžÄ°Ã–ÅžÃœ]{1,4}\s*\d{2,5})', content_raw, re.IGNORECASE)
    if pl_match:
        plate = pl_match.group(1).replace(" ", "")
    
    # Marka - "Marka : TOFAS-FIAT (100)"
    brand = "-"
    brand_match = re.search(r'Marka\s*[:\s]*([A-ZÃ‡ÄžÄ°Ã–ÅžÃœa-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼\-]+)', content_raw)
    if brand_match:
        brand = brand_match.group(1).strip().upper()
        # Parantez iÃ§indeki kodu temizle
        brand = re.sub(r'\s*\(\d+\)', '', brand).strip()
    
    # Tutar - "Ã–denecek Prim ... 6,865.44 TL"
    amount = "0"
    amt_match = re.search(r'Ã–denecek\s*Prim\s*[:\s]*([\d\.,]+)\s*TL', content_raw, re.IGNORECASE)
    if amt_match:
        amount = normalize_amount_to_turkish(amt_match.group(1))
    else:
        # Alternatif: Ã–DEME PLANI altÄ±ndaki tutar
        amt_match2 = re.search(r'PEÅžÄ°NAT\s*[:\s]*\d{2}/\d{2}/\d{4}\s*([\d\.,]+)\s*TL', content_raw)
        if amt_match2:
            amount = normalize_amount_to_turkish(amt_match2.group(1))
        else:
            amount = extract_amount(content)
    
    return {"SÄ°GORTALI": insured_name, "TARÄ°H": date, "MÃœÅžTERÄ° NO": "-", "POLÄ°Ã‡E NO": policy_no, "TÃœR": "TRAFÄ°K", "PLAKA": plate, "MARKA": brand, "TUTAR": amount, "ÅžÄ°RKET": "ALLIANZ"}

def process_allianz_kasko(pdf_path, filename):
    """Allianz Kasko PoliÃ§esi - GeniÅŸletilmiÅŸ Kasko"""
    full_text = ""
    lines = []
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages[:4]:
                text = page.extract_text()
                if text:
                    full_text += text + " "
                    lines.extend(text.split('\n'))
    except Exception as e:
        if sys.stdout:
            print(f"LOG: ALLIANZ KASKO PDF okuma hatasÄ± ({filename}): {type(e).__name__}")
        return None
    
    if not full_text.strip():
        if sys.stdout:
            print(f"LOG: ALLIANZ KASKO PDF boÅŸ iÃ§erik ({filename})")
        return None
    
    tr_map = {ord('i'): 'Ä°', ord('Ä±'): 'I', ord('ÄŸ'): 'Äž', ord('Ã¼'): 'Ãœ', ord('ÅŸ'): 'Åž', ord('Ã¶'): 'Ã–', ord('Ã§'): 'Ã‡'}
    content = clean_text(full_text).translate(tr_map).upper()
    content_raw = clean_text(full_text)
    
    # SigortalÄ± AdÄ± - FarklÄ± formatlar
    insured_name = "-"
    # Format 1: "SigortalÄ± AdÄ±/UnvanÄ± : Tarkan Åžahin"
    name_match = re.search(r'SigortalÄ±\s*AdÄ±/UnvanÄ±\s*[:\s]*([A-ZÃ‡ÄžÄ°Ã–ÅžÃœa-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼\s\.]+?)(?=\s*TCKN|T\.C\.|VKN|\d{10})', content_raw)
    if name_match:
        insured_name = name_match.group(1).strip()
    else:
        # Format 2: "SayÄ±n Tarkan Åžahin ,"
        sayin_match = re.search(r'SayÄ±n\s+([A-ZÃ‡ÄžÄ°Ã–ÅžÃœa-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼\s\.]+?)\s*[,\.]', content_raw)
        if sayin_match:
            insured_name = sayin_match.group(1).strip()
    
    # PoliÃ§e No - "PoliÃ§e No: 0001-0210-63400081"
    policy_no = "-"
    pol_match = re.search(r'PoliÃ§e\s*No[:\s]*(\d{4}-\d{4}-\d{8})', content_raw, re.IGNORECASE)
    if pol_match:
        policy_no = pol_match.group(1)
    else:
        # Alternatif format
        pol_match2 = re.search(r"no'lu\s*Allianz\s*Kasko.*?(\d{4}-\d{4}-\d{8})", content_raw, re.IGNORECASE)
        if pol_match2:
            policy_no = pol_match2.group(1)
        else:
            pol_match3 = re.search(r'(\d{4}-\d{4}-\d{8})', content_raw)
            if pol_match3:
                policy_no = pol_match3.group(1)
    
    # BaÅŸlangÄ±Ã§ Tarihi - "BaÅŸlangÄ±Ã§ Tarihi : 03/01/2026 12:00"
    date = "-"
    date_match = re.search(r'BaÅŸlangÄ±Ã§\s*Tarihi\s*[:\s]*(\d{2}/\d{2}/\d{4})', content_raw, re.IGNORECASE)
    if date_match:
        date = date_match.group(1)
    
    # Plaka No - "Plaka No : 34 HSB 518"
    plate = "-"
    pl_match = re.search(r'Plaka\s*No\s*[:\s]*(\d{2,3}\s*[A-ZÃ‡ÄžÄ°Ã–ÅžÃœ]{1,4}\s*\d{2,5})', content_raw, re.IGNORECASE)
    if pl_match:
        plate = pl_match.group(1).replace(" ", "")
    else:
        # Alternatif: "34 HSB 518 plakalÄ±" formatÄ±
        pl_match2 = re.search(r'(\d{2}\s*[A-ZÃ‡ÄžÄ°Ã–ÅžÃœ]{2,4}\s*\d{2,4})\s*plakalÄ±', content_raw, re.IGNORECASE)
        if pl_match2:
            plate = pl_match2.group(1).replace(" ", "")
    
    # Marka - "Marka : VOLKSWAGEN (153)"
    brand = "-"
    brand_match = re.search(r'Marka\s*[:\s]*([A-ZÃ‡ÄžÄ°Ã–ÅžÃœa-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼\-]+)', content_raw)
    if brand_match:
        brand = brand_match.group(1).strip().upper()
        brand = re.sub(r'\s*\(\d+\)', '', brand).strip()
    else:
        # Alternatif: "VOLKSWAGEN (153) marka" formatÄ±
        brand_match2 = re.search(r'([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ]+)\s*\(\d+\)\s*marka', content_raw, re.IGNORECASE)
        if brand_match2:
            brand = brand_match2.group(1).strip().upper()
    
    # Tutar - "Ã–DENECEK PRÄ°M : 21,372.17 TL" veya "BrÃ¼t Prim : 21,372.17 TL"
    amount = "0"
    amt_match = re.search(r'Ã–DENECEK\s*PRÄ°M\s*[:\s]*([\d\.,]+)\s*TL', content_raw, re.IGNORECASE)
    if amt_match:
        amount = normalize_amount_to_turkish(amt_match.group(1))
    else:
        amt_match2 = re.search(r'BrÃ¼t\s*Prim\s*[:\s]*([\d\.,]+)\s*TL', content_raw, re.IGNORECASE)
        if amt_match2:
            amount = normalize_amount_to_turkish(amt_match2.group(1))
        else:
            amt_match3 = re.search(r'Toplam\s*Prim\s*[:\s]*([\d\.,]+)\s*TL', content_raw, re.IGNORECASE)
            if amt_match3:
                amount = normalize_amount_to_turkish(amt_match3.group(1))
            else:
                amount = extract_amount(content)
    
    return {"SÄ°GORTALI": insured_name, "TARÄ°H": date, "MÃœÅžTERÄ° NO": "-", "POLÄ°Ã‡E NO": policy_no, "TÃœR": "KASKO", "PLAKA": plate, "MARKA": brand, "TUTAR": amount, "ÅžÄ°RKET": "ALLIANZ"}

def process_seyahat(pdf_path, filename):
    text = ""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages[:2]: text += page.extract_text() + " || "
    except: return None
    content = clean_text(text)
    insured_name = "-"
    name_match = re.search(r'SigortalÄ±nÄ±n\s*AdÄ±\s*SoyadÄ±\s*[:\s]*([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ\s\.]+?)(?=\s*(?:SigortalÄ±nÄ±n\s*Adresi|Adres|Kimlik|RÄ°SK))', content, re.IGNORECASE)
    if name_match: insured_name = name_match.group(1).strip()
    date = "-"
    d_match = re.search(r'(?:BaÅŸlangÄ±Ã§|Tanzim)\s*Tarihi\s*[:\s]*(\d{2}/\d{2}/\d{4})', content, re.IGNORECASE)
    if d_match: date = d_match.group(1)
    policy_no = "-"
    pol = re.search(r'PoliÃ§e\s*No\s*[:\s]*(\d{7,})', content, re.IGNORECASE)
    if pol: policy_no = pol.group(1)
    cust_no = "-"
    cust = re.search(r'MÃ¼ÅŸteri\s*No\s*[:\s]*(\d{6,15})', content, re.IGNORECASE)
    if cust: cust_no = cust.group(1)
    amount = "0"
    amount_match = re.search(r'Ã–denecek\s*Prim\s*[:\s]*([\d,]+)', content, re.IGNORECASE)
    if amount_match: amount = amount_match.group(1) + " EUR"
    return {"SÄ°GORTALI": insured_name, "TARÄ°H": date, "MÃœÅžTERÄ° NO": cust_no, "POLÄ°Ã‡E NO": policy_no, "TÃœR": "SEYAHAT", "PLAKA": "-", "MARKA": "-", "TUTAR": amount, "ÅžÄ°RKET": "AXA"}

def process_isyeri(pdf_path, filename):
    text = ""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages[:2]: text += page.extract_text() + " || "
    except: return None
    content = clean_text(text)
    insured_name = "-"
    name_match = re.search(r'SigortalÄ±nÄ±n\s*AdÄ±\s*SoyadÄ±\s*[:\s]*([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ\s\.]+?)(?=\s*SigortalÄ±nÄ±n\s*Adresi)', content, re.IGNORECASE)
    if name_match: insured_name = name_match.group(1).strip()
    date = "-"
    d_match = re.search(r'(?:BaÅŸlangÄ±Ã§|Tanzim)\s*Tarihi\s*[:\s]*(\d{2}/\d{2}/\d{4})', content, re.IGNORECASE)
    if d_match: date = d_match.group(1)
    policy_no = "-"
    pol = re.search(r'PoliÃ§e\s*No\s*[:\s]*(\d{7,})', content, re.IGNORECASE)
    if pol: policy_no = pol.group(1)
    cust_no = "-"
    cust = re.search(r'MÃ¼ÅŸteri\s*No\s*[:\s]*(\d{6,15})', content, re.IGNORECASE)
    if cust: cust_no = cust.group(1)
    faaliyet = "-"
    f_match = re.search(r'Faaliyet\s*Konusu\s*[:\s]*([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ\s]+?)(?=\s*YapÄ±\s*TarzÄ±)', content, re.IGNORECASE)
    if f_match: faaliyet = f_match.group(1).strip()
    amount = extract_amount(content)
    return {"SÄ°GORTALI": insured_name, "TARÄ°H": date, "MÃœÅžTERÄ° NO": cust_no, "POLÄ°Ã‡E NO": policy_no, "TÃœR": "Ä°ÅžYERÄ°", "PLAKA": "-", "MARKA": faaliyet, "TUTAR": amount, "ÅžÄ°RKET": "AXA"}

def process_nakliyat(pdf_path, filename):
    text = ""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages[:2]: text += page.extract_text() + " || "
    except: return None
    content = clean_text(text)
    insured_name = "-"
    name_match = re.search(r'SigortalÄ±nÄ±n\s*AdÄ±\s*SoyadÄ±\s*[:\s]*([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ\s\.]+?)(?=\s*SigortalÄ±nÄ±n\s*Adresi)', content, re.IGNORECASE)
    if name_match: insured_name = name_match.group(1).strip()
    date = "-"
    d_match = re.search(r'(?:BaÅŸlangÄ±Ã§|Tanzim)\s*Tarihi\s*[:\s]*(\d{2}/\d{2}/\d{4})', content, re.IGNORECASE)
    if d_match: date = d_match.group(1)
    policy_no = "-"
    pol = re.search(r'PoliÃ§e\s*No\s*[:\s]*(\d{7,})', content, re.IGNORECASE)
    if pol: policy_no = pol.group(1)
    cust_no = "-"
    cust = re.search(r'MÃ¼ÅŸteri\s*No\s*[:\s]*(\d{6,15})', content, re.IGNORECASE)
    if cust: cust_no = cust.group(1)
    plate = "-"
    pl_match = re.search(r'(?:Kamyon|Ã‡ekici|AraÃ§)\s*PlakasÄ±\s*[:\s]*([0-9]{2}\s*[A-Z]{1,4}\s*\d{2,5})', content, re.IGNORECASE)
    if pl_match: plate = pl_match.group(1).replace(" ", "")
    amount = extract_amount(content)
    return {"SÄ°GORTALI": insured_name, "TARÄ°H": date, "MÃœÅžTERÄ° NO": cust_no, "POLÄ°Ã‡E NO": policy_no, "TÃœR": "NAKLÄ°YAT", "PLAKA": plate, "MARKA": "-", "TUTAR": amount, "ÅžÄ°RKET": "AXA"}

def process_konut(pdf_path, filename):
    text = ""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages[:2]: text += page.extract_text() + " || "
    except: return None
    content = clean_text(text)
    insured_name = "-"
    name_match = re.search(r'SigortalÄ±nÄ±n\s*AdÄ±\s*SoyadÄ±\s*[:\s]*([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ\s\.]+?)(?=\s*SigortalÄ±nÄ±n\s*Adresi)', content, re.IGNORECASE)
    if name_match: insured_name = name_match.group(1).strip()
    if insured_name == "-" or len(insured_name) < 3:
        sm = re.search(r'SayÄ±n\s+([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ\s]{3,50})', content)
        if sm: insured_name = sm.group(1).strip()
    date = "-"
    d_match = re.search(r'(?:BaÅŸlangÄ±Ã§|Tanzim)\s*Tarihi\s*[:\s]*(\d{2}/\d{2}/\d{4})', content, re.IGNORECASE)
    if d_match: date = d_match.group(1)
    policy_no = "-"
    pol = re.search(r'PoliÃ§e\s*No\s*[:\s]*(\d{7,})', content, re.IGNORECASE)
    if pol: policy_no = pol.group(1)
    cust_no = "-"
    cust = re.search(r'MÃ¼ÅŸteri\s*No\s*[:\s]*(\d{6,15})', content, re.IGNORECASE)
    if cust: cust_no = cust.group(1)
    amount = extract_amount(content)
    return {"SÄ°GORTALI": insured_name, "TARÄ°H": date, "MÃœÅžTERÄ° NO": cust_no, "POLÄ°Ã‡E NO": policy_no, "TÃœR": "EVÄ°M", "PLAKA": "-", "MARKA": "-", "TUTAR": amount, "ÅžÄ°RKET": "AXA"}

def process_saglik(pdf_path, filename):
    text = ""
    try:
        reader = PdfReader(pdf_path)
        for page in reader.pages[:3]: text += page.extract_text() + " "
    except: return None
    content = clean_text(text)
    date = "-"
    date_match = re.search(r'(?:BAÅžLANGIÃ‡|TANZÄ°M)\s*TARÄ°HÄ°.*?(\d{2}/\d{2}/\d{4})', content, re.IGNORECASE)
    if date_match: date = date_match.group(1)
    policy_no = "-"
    pol_match = re.search(r'PoliÃ§e\s*No\s*[:\-\s]*(\d{7,})', content, re.IGNORECASE)
    if pol_match: policy_no = pol_match.group(1)
    else:
        f_num = re.search(r'(\d{7,})', filename)
        if f_num: policy_no = f_num.group(1)
    insured_name = "-"
    cust_no = "-"
    table_match = re.search(r'(\d{7,})\s+([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ\s]{3,40})\s+(?:KE|EÅž|Ã‡OCUK)', content)
    if table_match:
        raw_no = table_match.group(1)
        if "6552" not in raw_no:
            cust_no = raw_no
            insured_name = table_match.group(2).strip()
    if insured_name == "-":
        lbl_match = re.search(r'(?:ADI\s*SOYADI|SÄ°GORTALI)\s*[:]*\s*([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ\s]{3,40})(?=\s+(?:ADRES|TELEFON))', content, re.IGNORECASE)
        if lbl_match: insured_name = lbl_match.group(1).strip()
    blacklist = ["ADRES", "TELEFON", "MÃœÅžTERÄ°", "ACENTE", "SÄ°GORTA", "Ä°STANBUL", "TÃœRKÄ°YE", "NO:"]
    if any(x in insured_name for x in blacklist):
        for bad in blacklist: insured_name = insured_name.replace(bad, "")
    amount = extract_amount(content)
    return {"SÄ°GORTALI": insured_name.strip(), "TARÄ°H": date, "MÃœÅžTERÄ° NO": cust_no, "POLÄ°Ã‡E NO": policy_no, "TÃœR": "SAÄžLIK", "PLAKA": "-", "MARKA": "-", "TUTAR": amount, "ÅžÄ°RKET": "AXA"}

def process_dask(pdf_path, filename):
    text = ""
    try:
        reader = PdfReader(pdf_path)
        for page in reader.pages[:2]: text += page.extract_text() + " "
    except: return None
    content = clean_text(text)
    
    # SÄ°GORTA ETTÄ°REN BÄ°LGÄ°LERÄ° altÄ±ndaki AdÄ± SoyadÄ±
    insured_name = "-"
    name_match = re.search(r'SÄ°GORTA\s*ETTÄ°REN\s*BÄ°LGÄ°LERÄ°.*?AdÄ±\s*SoyadÄ±[/:]?\s*UnvanÄ±?\s*[:\s]*([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ\.,\s]{3,80})(?=\s*(?:TCKN|VKN|Cep|Sabit|E-posta))', content, re.IGNORECASE | re.DOTALL)
    if name_match: insured_name = name_match.group(1).strip()
    
    date = "-"
    date_match = re.search(r'BaÅŸlangÄ±Ã§\s*Tarihi\s*[:\s]*(\d{2}/\d{2}/\d{4})', content, re.IGNORECASE)
    if date_match: date = date_match.group(1)
    
    # Sigorta Åžirketi PoliÃ§e No (SIGORTACI / ARACI BÄ°LGÄ°LERÄ° kÄ±smÄ±ndaki)
    policy_no = "-"
    sirket_pol = re.search(r'Sigorta\s*Åžirketi\s*PoliÃ§e\s*No\s*[:\s]*(\d+)', content, re.IGNORECASE)
    if sirket_pol: policy_no = sirket_pol.group(1)
    
    amount = extract_amount(content)
    return {"SÄ°GORTALI": insured_name, "TARÄ°H": date, "MÃœÅžTERÄ° NO": "-", "POLÄ°Ã‡E NO": policy_no, "TÃœR": "DASK", "PLAKA": "-", "MARKA": "-", "TUTAR": amount, "ÅžÄ°RKET": "AXA"}

def process_vehicle(pdf_path, filename, p_type):
    text = ""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages[:2]: text += page.extract_text() + " || "
    except: return None
    content = clean_text(text)
    insured_name = "-"
    # Ä°ki nokta olsun ya da olmasÄ±n, ismi yakala
    name_match = re.search(r'SigortalÄ±nÄ±n\s*AdÄ±\s*SoyadÄ±\s*[:\s]+([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ\s\.\-]+?)(?=\s*(?:SigortalÄ±nÄ±n\s*Adresi|Adres|Kimlik|Vergi))', text.replace("||", " "), re.IGNORECASE)
    if name_match: 
        insured_name = re.sub(r'[\|:.]', '', name_match.group(1)).strip()
        # Sadece "L" gibi tek harf kalmÄ±ÅŸsa, dosya adÄ±ndan kullan
        if len(insured_name) < 3: insured_name = "-"
    date = "-"
    date_match = re.search(r'BaÅŸlangÄ±Ã§\s*Tarihi.*?(\d{2}/\d{2}/\d{4})', content, re.IGNORECASE)
    if date_match: date = date_match.group(1)
    cust_no = "-"
    cust_match = re.search(r'MÃ¼ÅŸteri\s*No\s*[:\s]*(\d{5,15})', content, re.IGNORECASE)
    if cust_match: cust_no = cust_match.group(1)
    policy_no = "-"
    pol_match = re.search(r'(?<!Eski\s)Poli[Ã§c]e\s*No\s*[:\s]*(\d{8,9})', content, re.IGNORECASE)
    if pol_match: policy_no = pol_match.group(1)
    plate = "-"
    plate_match = re.search(r'Plaka\s*No.*?\s*([0-9]{2}\s*[A-Z]{1,5}\s*[0-9]{2,5})', content, re.IGNORECASE)
    if plate_match: plate = plate_match.group(1).replace(" ", "")
    brand = "-"
    brand_match = re.search(r'Marka\s*[:\s]*([A-ZÃ‡ÄžÄ°Ã–ÅžÃœ\s\(\)\-]{3,30})(?=\s*(?:Model|Tipi|KullanÄ±m))', text.replace("||", " "), re.IGNORECASE)
    if brand_match:
        raw = brand_match.group(1).strip()
        brand = re.sub(r'MARKA', '', raw, flags=re.IGNORECASE).strip()
        if "SÄ°GORTA" in brand: brand = "-"
    amount = extract_amount(content)
    return {"SÄ°GORTALI": insured_name, "TARÄ°H": date, "MÃœÅžTERÄ° NO": cust_no, "POLÄ°Ã‡E NO": policy_no, "TÃœR": p_type, "PLAKA": plate, "MARKA": brand, "TUTAR": amount, "ÅžÄ°RKET": "AXA"}

# ==============================================================================
# ðŸš€ ANA Ã‡ALIÅžTIRMA BLOÄžU
# ==============================================================================
def main():
    if len(sys.argv) < 2:
        print(json.dumps({"status": "error", "message": "Eksik parametre."}))
        return
    
    # --- ARAMA MODU (C# TarafÄ±ndan Ã‡aÄŸrÄ±ldÄ±ÄŸÄ±nda) ---
    if sys.argv[1].upper() == "SEARCH":
        if len(sys.argv) < 3:
            print(json.dumps({"status": "error", "message": "VeritabanÄ± yolu gerekli."}))
            return
        
        db_path = sys.argv[2]
        if not os.path.exists(db_path):
            print(json.dumps({"status": "error", "message": "VeritabanÄ± dosyasÄ± bulunamadÄ±!"}))
            return
        
        search_params = {}
        for i in range(3, len(sys.argv)):
            if "=" in sys.argv[i]:
                key, value = sys.argv[i].split("=", 1)
                if value.strip(): search_params[key.lower()] = value.strip()
        
        if not search_params:
            print(json.dumps({"status": "error", "message": "Arama kriteri belirtilmedi."}))
            return
        
        try:
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            where_conditions = []
            params = []
            
            if "musteri_no" in search_params:
                where_conditions.append("musteri_no LIKE ? AND musteri_no != '-'")
                params.append(f"%{search_params['musteri_no']}%")
            if "isim" in search_params:
                where_conditions.append("sigortali LIKE ? AND sigortali != '-'")
                params.append(f"%{search_params['isim']}%")
            if "police_no" in search_params:
                where_conditions.append("police_no LIKE ? AND police_no != '-'")
                params.append(f"%{search_params['police_no']}%")
            if "plaka" in search_params:
                where_conditions.append("plaka LIKE ? AND plaka != '-'")
                params.append(f"%{search_params['plaka']}%")
            if "tarih_baslangic" in search_params and "tarih_bitis" in search_params:
                where_conditions.append("tarih BETWEEN ? AND ? AND tarih != '-'")
                params.extend([search_params['tarih_baslangic'], search_params['tarih_bitis']])
            elif "tarih" in search_params:
                where_conditions.append("tarih LIKE ? AND tarih != '-'")
                params.append(f"%{search_params['tarih']}%")
            if "tur" in search_params:
                where_conditions.append("tur LIKE ?")
                params.append(f"%{search_params['tur']}%")
            
            where_clause = " AND ".join(where_conditions) if where_conditions else "1=1"
            query = f"""
            SELECT sigortali, tarih, musteri_no, police_no, tur, sirket, plaka, marka, tutar, aciklama
            FROM policeler 
            WHERE {where_clause}
            ORDER BY kayit_tarihi DESC
            LIMIT 100
            """
            cursor.execute(query, params)
            results = cursor.fetchall()
            conn.close()
            
            data = []
            for row in results:
                data.append({
                    'SÄ°GORTALI': row[0], 'TARÄ°H': row[1], 'MÃœÅžTERÄ° NO': row[2], 'POLÄ°Ã‡E NO': row[3],
                    'TÃœR': row[4], 'ÅžÄ°RKET': row[5], 'PLAKA': row[6], 'MARKA': row[7], 
                    'TUTAR': row[8], 'AÃ‡IKLAMA': row[9]
                })
            
            print(json.dumps({"status": "success", "count": len(data), "data": data, "message": f"{len(data)} sonuÃ§ bulundu."}))
            
        except Exception as e:
            print(json.dumps({"status": "error", "message": f"Sorgu hatasÄ±: {str(e)}"}))
        return

    # --- NORMAL MOD - PDF Ä°ÅžLEME ve KAYIT ---
    if len(sys.argv) < 4:
        print(json.dumps({"status": "error", "message": "Eksik parametre. KullanÄ±m: engine.exe <Kaynak> <Ã‡Ä±ktÄ±> <KullanÄ±cÄ±>"}))
        return

    source_folder = sys.argv[1]
    output_folder = sys.argv[2]
    user_name = sys.argv[3]
    excel_name = "POLÄ°Ã‡ELER.xlsx"
    excel_path = os.path.join(output_folder, excel_name)
    # 4. parametre varsa (C# tarafÄ±ndan gÃ¶nderilen DB yolu), onu kullan
    if len(sys.argv) >= 5:
        db_path = sys.argv[4]
    else:
        db_name = "POLICELER.db"
        db_path = os.path.join(output_folder, db_name)
    
    if not init_database(db_path):
        print(json.dumps({"status": "error", "message": "VeritabanÄ± oluÅŸturulamadÄ±!"}))
        return
    
    if not os.path.exists(source_folder):
        print(json.dumps({"status": "error", "message": "Kaynak klasÃ¶r bulunamadÄ±!"}))
        return

    # 1. Mevcut Verileri Oku
    existing_policies = set()
    existing_records = set()  # SÄ°GORTALI+TARÄ°H iÃ§in
    df_existing_master = pd.DataFrame()
    if os.path.exists(excel_path):
        try:
            df_existing_master = pd.read_excel(excel_path)
            if "POLÄ°Ã‡E NO" in df_existing_master.columns:
                for idx, row in df_existing_master.iterrows():
                    p_no = str(row.get("POLÄ°Ã‡E NO", "")).strip()
                    if p_no and p_no not in ("-", "nan", "None"):
                        existing_policies.add(p_no)
                    # Alternatif kontrol: SÄ°GORTALI + TARÄ°H + TÃœR kombinasyonu
                    sigortali = str(row.get("SÄ°GORTALI", "")).strip()
                    tarih = str(row.get("TARÄ°H", "")).strip()
                    tur = str(row.get("TÃœR", "")).strip()
                    if sigortali and tarih and tur:
                        existing_records.add(f"{sigortali}_{tarih}_{tur}")
        except Exception as e:
            if sys.stdout: print(f"LOG: Excel okuma uyarÄ±sÄ±: {str(e)}", flush=True)

    # 2. PDF'leri Ä°ÅŸle
    files = [f for f in os.listdir(source_folder) if f.lower().endswith('.pdf')]
    current_batch_data = []

    for file in files:
        file_path = os.path.join(source_folder, file)
        doc_type = identify_policy_type(file_path)
        data = None

        try:
            if doc_type == "TRAFÄ°K_HDI": data = process_hdi_trafik(file_path, file)
            elif doc_type == "TRAFÄ°K_HDI_YENI": data = hdi_yeni_police(file_path, file)
            elif doc_type == "TRAFÄ°K_ETHICA": data = process_ethica_trafik(file_path, file)
            elif doc_type == "TRAFÄ°K_SOMPO": data = process_sompo_trafik(file_path, file)
            elif doc_type == "TRAFÄ°K_QUICK": data = process_quick_trafik(file_path, file)
            elif doc_type == "TRAFÄ°K_DOÄžA": data = process_doga_trafik(file_path, file)
            elif doc_type == "TRAFÄ°K_HEPÄ°YÄ°": data = process_hepiyi_trafik(file_path, file)
            elif doc_type == "TRAFÄ°K_RAY": data = process_ray_trafik(file_path, file)
            elif doc_type == "TRAFÄ°K_ALLIANZ": data = process_allianz_trafik(file_path, file)
            elif doc_type == "KASKO_ALLIANZ": data = process_allianz_kasko(file_path, file)
            elif doc_type == "SEYAHAT": data = process_seyahat(file_path, file)
            elif doc_type == "SAÄžLIK": data = process_saglik(file_path, file)
            elif doc_type == "EVÄ°M": data = process_konut(file_path, file)
            elif doc_type == "NAKLÄ°YAT": data = process_nakliyat(file_path, file)
            elif doc_type == "Ä°ÅžYERÄ°": data = process_isyeri(file_path, file)
            elif doc_type == "DASK": data = process_dask(file_path, file)
            elif doc_type == "TRAFÄ°K": data = process_vehicle(file_path, file, "TRAFÄ°K")
            elif doc_type == "KASKO": data = process_vehicle(file_path, file, "KASKO")
            else: data = {"SÄ°GORTALI": file, "TÃœR": "TANIMSIZ", "TUTAR": "-", "ÅžÄ°RKET": "-", "POLÄ°Ã‡E NO": "-", "TARÄ°H": "-", "MÃœÅžTERÄ° NO": "-", "PLAKA": "-", "MARKA": "-"}

            if data:
                if data.get('SÄ°GORTALI') == "-" or data.get('SÄ°GORTALI') is None:
                    data['SÄ°GORTALI'] = file.replace(".pdf", "")[:25]
                data["AÃ‡IKLAMA"] = user_name
                p_no = str(data.get('POLÄ°Ã‡E NO', '')).strip()
                
                # Duplikasyon kontrolÃ¼ 1: POLÄ°Ã‡E NO ile
                if p_no and p_no not in ("-", "nan", "None") and p_no in existing_policies:
                    if sys.stdout: print(f"LOG:{data['SÄ°GORTALI']} - {data['TÃœR']} -> MEVCUT (POLÄ°Ã‡E NO: {p_no})", flush=True)
                    continue
                
                # Duplikasyon kontrolÃ¼ 2: SÄ°GORTALI + TARÄ°H + TÃœR ile (poliÃ§e no yoksa)
                sigortali = str(data.get('SÄ°GORTALI', '')).strip()
                tarih = str(data.get('TARÄ°H', '')).strip()
                tur = str(data.get('TÃœR', '')).strip()
                record_key = f"{sigortali}_{tarih}_{tur}"
                if record_key in existing_records:
                    if sys.stdout: print(f"LOG:{data['SÄ°GORTALI']} - {data['TÃœR']} -> MEVCUT (Ä°Ã§erik)", flush=True)
                    continue
                
                # AynÄ± batch iÃ§inde tekrar kontrolÃ¼
                if p_no and p_no not in ("-", "nan", "None"):
                    batch_has_duplicate = any(str(item.get('POLÄ°Ã‡E NO', '')).strip() == p_no for item in current_batch_data)
                    if batch_has_duplicate:
                        if sys.stdout: print(f"LOG:{data['SÄ°GORTALI']} - {data['TÃœR']} -> TEKRAR (Batch)", flush=True)
                        continue
                    existing_policies.add(p_no)
                
                # Batch iÃ§inde iÃ§erik kontrolÃ¼
                batch_has_content = any(f"{str(item.get('SÄ°GORTALI', '')).strip()}_{str(item.get('TARÄ°H', '')).strip()}_{str(item.get('TÃœR', '')).strip()}" == record_key for item in current_batch_data)
                if batch_has_content:
                    if sys.stdout: print(f"LOG:{data['SÄ°GORTALI']} - {data['TÃœR']} -> TEKRAR (Ä°Ã§erik Batch)", flush=True)
                    continue
                
                existing_records.add(record_key)
                current_batch_data.append(data)
                if sys.stdout: print(f"LOG:{data['SÄ°GORTALI']} - {data['TÃœR']} ({data['TUTAR']}) -> LÄ°STEYE ALINDI", flush=True)
        except Exception as e:
            if sys.stdout: print(f"LOG:{file} -> HATA: {str(e)}", flush=True)
            continue

    # 3. Kaydet
    if current_batch_data:
        df_new_entries = pd.DataFrame(current_batch_data)
        bad_words = ["SigortalÄ±nÄ±n", "AdÄ±", "SoyadÄ±", "Adresi", ":", "MÃ¼ÅŸteri", "UnvanÄ±", "NO", "ACENTE", "Sigc", "SayÄ±n"]
        if "SÄ°GORTALI" in df_new_entries.columns:
            for bad in bad_words:
                 df_new_entries["SÄ°GORTALI"] = df_new_entries["SÄ°GORTALI"].astype(str).str.replace(bad, "", regex=True, flags=re.IGNORECASE).str.strip()

        cols_order = ["SÄ°GORTALI", "TARÄ°H", "MÃœÅžTERÄ° NO", "POLÄ°Ã‡E NO", "TÃœR", "ÅžÄ°RKET", "PLAKA", "MARKA", "TUTAR", "AÃ‡IKLAMA", "REFERANS", "Ä°LETÄ°ÅžÄ°M"]
        for c in cols_order:
            if c not in df_new_entries.columns: df_new_entries[c] = "-"
        df_new_entries = df_new_entries[cols_order]

        try:
            if not df_existing_master.empty: df_final = pd.concat([df_existing_master, df_new_entries], ignore_index=True)
            else: df_final = df_new_entries
            
            # SÄ±ra numarasÄ± ekle (baÅŸlÄ±k hariÃ§, ilk PDF = 1)
            df_final.insert(0, 'SIRA', range(1, len(df_final) + 1))
            
            with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
                df_final.to_excel(writer, index=False, sheet_name="TÃœM POLÄ°Ã‡ELER")
                ws = writer.sheets["TÃœM POLÄ°Ã‡ELER"]
                
                # TÃ¼m sÃ¼tunlarÄ± iÃ§eriÄŸe gÃ¶re otomatik ayarla
                column_widths = {
                    'A': 8,   # SIRA - yeni sÃ¼tun
                    'B': 35,  # SÄ°GORTALI - uzun isimler iÃ§in
                    'C': 12,  # TARÄ°H
                    'D': 15,  # MÃœÅžTERÄ° NO
                    'E': 18,  # POLÄ°Ã‡E NO
                    'F': 12,  # TÃœR
                    'G': 12,  # ÅžÄ°RKET
                    'H': 15,  # PLAKA
                    'I': 20,  # MARKA
                    'J': 15,  # TUTAR
                    'K': 15,  # AÃ‡IKLAMA
                    'L': 15,  # REFERANS
                    'M': 15   # Ä°LETÄ°ÅžÄ°M
                }
                
                for col, width in column_widths.items():
                    ws.column_dimensions[col].width = width

            db_added = insert_police_data(db_path, current_batch_data)
            print(json.dumps({
                "status": "success", "added": len(df_new_entries), "db_added": db_added,
                "message": f"{len(df_new_entries)} yeni kayÄ±t eklendi.\nExcel: Tek Liste GÃ¼ncellendi.\nSQLite: GÃ¼ncellendi.",
                "path": excel_path, "db_path": db_path
            }))
        except Exception as e:
            print(json.dumps({"status": "error", "message": f"Dosya yazma hatasÄ±: {str(e)}"}))
    else:
        print(json.dumps({"status": "success", "added": 0, "message": "Eklenecek yeni poliÃ§e bulunamadÄ±."}))

if __name__ == "__main__":
    main()